## **머신러닝 모델 평가 지표 - 회귀모델**

머신러닝, 딥러닝에서 평가지표로 **손실함수**를 사용한다. **손실 함수의 값이 작아질수록,** 모델의 **예측 성능은 좋아진다.**

따라서 모델의 성능을 향상하기 위해 **손실함수를 최소화** 해야한다. 따라서 아래와 같은 **손실함수, 평가지표**를 사용한다.

 

------

### **회귀****(Regression)** **모델** **평가** **지표 요약**

아래의 평가지표는 분류(Yes/No)가 아니라, **회귀 모델**. 즉 , **실수 기반의 결과**에 대한 오차를 판별하는 지표이다.

- **MSE (Mean Squared Error, 평균제곱오차**) : 예측값과 실제값 간의 차이를 제곱하여 평균한 값, 오차 제곱의 평균
- **RMSE (Root Mean Squared Error, 평균 제곱근 오차)**:MSE의 제곱근으로, 예측값과 실제값 간의 차이를 평균적으로 얼마나 벗어났는지를 나타냄
- **MAE(Mean Absolute Error, 평균 절대 오차)**:예측값과 실제값 간의 절대적인 차이를 평균한 값, 오차의 절댓값의 평균
- **R-squared(R²)**:회귀 모델의 설명력을 나타내는 지표로, 0과 1 사이의 값을 가지며 1에 가까울수록 모델이 데이터를 잘 설명함

 

------

### **1. MSE , RMSE, MAE 평가지표 개념**

####  

**MSE(\**Mean Squared Error)는\**** **오차**(실제값과 예측값의 차이)를 **제곱**하여 평균한 값이다.

각각의 데이터 포인트에서 예측값과 실제값의 차이를 제곱한 후, **모든 데이터 포인트의 평균**을 내는 방식으로 구한다.

오차를 제곱하는 방식이므로, **이상치에 민감**하다.

 

## **MSE = (1/n) \* Σ(yᵢ - ŷᵢ) ²**

yᵢ : 실제값

ŷᵢ: 예측값

 

**RMSE(\**Root Mean Squared Error)는\**** MSE의 제곱근으로, 예측값과 실제값 사이의 오차의 제곱에 루트를 씌운 값이다.

따라서 오차의 제곱인 MSE에 비해, **이상치에 덜 민감**하다고 할 수 있다.

 

## **RMSE = √((1/n) \* Σ(yᵢ - ŷᵢ) ²)**

 

**MAE(\**Mean Absolute Error)는\**** 모든 데이터 포인트에서 예측값과 실제값 사이의 오차를 **절댓값으로** 계산하고 이를 평균한 값입니다. 따라서 **MSE, RMSE 보다 이상치에 덜 민감**하다.

## **MAE = (1/n) \* Σ|yᵢ - ŷᵢ|**

------

### **MSE, RMSE, MAE 구현방법**

**직접 풀이**

**MSE : (실제값 - 예측값)^2/ 실제값 개수**

**MAE: |(실제값 - 예측값)| / 실제값 개수**

```
MSE = (test_value - predicted_value)^2 / len(test_value)
MAE = np.abs(tested_value - predicted_value) / len(v1)
```

**파이썬 라이브러리 활용 풀이**

**MSE : sklearn 모듈을 이용해서 mean_squared_error 함수 사용**

**RMSE : MSE에 np.sqrt()를 취하는 방식으로 계산**

**MAE : \**sklearn 모듈을 이용해서 mean_squared_error 함수 사용\****

```
# 넘파이, 사이킷런 모듈을 임포트
import numpy as np
from sklearn.metrics import mean_squared_error,mean_absolute_error

# MSE
mean_squared_error(test_value, predicted_value)

# RMSE
rmse = np.sqrt(mse)

# MAE
mean_absolute_error(tested_value, predicted_value)
```

------

### **손실함수 관점에서의 최적값 비교**

포스팅의 서두에 언급했듯이, 평가지표는 결국 손실함수이다. 손실함수 그래프를 통해, 각각의 평가지표에 대한 장단점을 알아본다.



![img](https://blog.kakaocdn.net/dn/bYUjsY/btst9afEI4Y/jWshxvw0XFecVWgjxRHnK0/img.png)https://bo-10000.tistory.com/44



왼쪽이 MAE, 오른쪽이 MSE이다. 

그래프에서 보다시피 MSE(오른쪽)는 미분을 통해 기울기가 0이 되는 최적값을 찾을 수 있는 반면, MAE는 최적값에 가까워지더라도 이동거리가 일정하기 때문에, 최적값에 수렴하기가 어렵다.

 

### **종합 비교**

|          | **이상치, 오차**                                             | **방향성**                                                   | **미분**                                                     |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **MSE**  | **오차의 제곱 > 이상치 영향 가장 큼** 예측 오차의 크기에 따라 패널티를 부여하여 이상치(outlier)에 민감함 |                                                              | **미분 가능** 수학적으로 계산하기가 간편하며, 경사 하강법 등을 사용한 최적화 가능 |
| **RMSE** | **MSE의 제곱근 > 이상치 영향 큼 **(오차의 크기를 원래 데이터의 단위로 변환 )  이상치에 대한 패널티는 여전히 크지만, MSE보다는 민감도 낮음 |                                                              | **미분 가능** 수학적으로 계산하기가 간편하며, 경사 하강법 등을 사용한 최적화 가능 |
| **MAE**  | **오차의 절댓값 > 이상치 영향 가장 작음**  이상치(outlier)에 대한 영향이 상대적으로 작음> 큰 오차를 갖는 이상치가 있더라도 MAE는 그 영향을 크게 받지 않음 | **방향성 무시(절댓값 사용) **오차의 크기만을 고려하고 방향성(양수 또는 음수)을 고려하지 않음 > 모델의 예측이 실제값보다 높을 때나 낮을 때나 동일한 패널티를 부여 | **미분 불가능(절댓값 계산) **수학적으로 미분 가능하지 않습니다. 일부 알고리즘에 제약적임, 최적화 어려움 |

