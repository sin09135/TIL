{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "348cd3e9-2dc0-427e-8bde-15649ba8a27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/movie_rv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6874de0-ac98-4590-b888-c735430a1aa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 텍스트 전처리\n",
    "- Python 문법으로 진행한 것은 > 데이터 정제하는 과정, 특수문자/기타 공백 제거\n",
    "- 정제 작업을 한 후에 한글/영어에 따라 전처리 진행\n",
    "- nltk 패키지로 학습\n",
    "- 토큰화 : 주어진 텍스트 단위를 나누는 작업\n",
    "    - 문장 토큰화\n",
    "    - 단어 토큰화 : 일반적인 토큰화작업\n",
    "\n",
    "- 정규화: go goes (주어에 따라 달라지는) 이런 것들을 하나로 정규화시켜서 통일해야 한다.\n",
    "    - 어간 추출, 표제어 추출\n",
    "    \n",
    "- 품사 태깅 : 명사, 대명사, 형용사 등으로 태깅하여 원하는 분석 요구에 따라 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f66ed7a-4b2e-43c0-bb93-279c7660aa7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d423d7a5-0b39-4261-a51c-a122c2bc271b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kimsinwoo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     /Users/kimsinwoo/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kimsinwoo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kimsinwoo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading average_perception_tagger: Package\n",
      "[nltk_data]     'average_perception_tagger' not found in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('webtext')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('average_perception_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec35d6-55de-4fef-9aa7-95222788c18d",
   "metadata": {},
   "source": [
    "### 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d843a85f-e93b-403c-98a1-329f2375cb62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize # 문장 토큰을 쉽게 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2700cb5b-de52-469d-b555-891e35159c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp1 = 'Machine Learning is a field of artificial intelligence where computers learn from data to discover patterns and perform tasks without being explicitly programmed. It enables computers to learn and improve from experience automatically. In general, the process of machine learning involves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abe8ed98-5d3e-43a7-96a2-6fb21b11fa72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine Learning is a field of artificial intelligence where computers learn from data to discover patterns and perform tasks without being explicitly programmed.', 'It enables computers to learn and improve from experience automatically.', 'In general, the process of machine learning involves']\n"
     ]
    }
   ],
   "source": [
    "# 주어진 문장 단위로 토큰\n",
    "print(sent_tokenize(sp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13798693-7134-4e31-bf60-d7c7a0b24734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b35d4092-4753-4031-b7c9-77e71cb50d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'Learning', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'where', 'computers', 'learn', 'from', 'data', 'to', 'discover', 'patterns', 'and', 'perform', 'tasks', 'without', 'being', 'explicitly', 'programmed', '.', 'It', 'enables', 'computers', 'to', 'learn', 'and', 'improve', 'from', 'experience', 'automatically', '.', 'In', 'general', ',', 'the', 'process', 'of', 'machine', 'learning', 'involves']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sp1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e11d4-0a38-4c22-99e5-40e7a316b081",
   "metadata": {},
   "source": [
    "- 느낌표, 기타 분리등 다양하게 분리할 수 있는 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2236fb68-35ac-4e15-a45e-4839a04ebf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer #특수문자 제거도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d473cfcf-ae5a-4ed0-82b2-6bed77922e26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'Learning', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'where', 'computers', 'learn', 'from', 'data', 'to', 'discover', 'patterns', 'and', 'perform', 'tasks', 'without', 'being', 'explicitly', 'programmed', '.', 'It', 'enables', 'computers', 'to', 'learn', 'and', 'improve', 'from', 'experience', 'automatically', '.', 'In', 'general', ',', 'the', 'process', 'of', 'machine', 'learning', 'involves']\n"
     ]
    }
   ],
   "source": [
    "print(WordPunctTokenizer().tokenize(sp1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede1f9c-bcc0-40b3-a800-2c04429230f7",
   "metadata": {},
   "source": [
    "### 정규표현식 토크나이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e65fd3c-d2ce-4b01-9eee-de1b8d442e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d729a627-76e9-456b-9d87-dd62487aebfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('[\\W\"]+') # 정규표현식 제거 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e0306f7-86f2-46c2-93a7-81a606437ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(tokenizer.tokenize(sp1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407705b-2d0a-44e8-820d-bedfbb03fa82",
   "metadata": {},
   "source": [
    "### 노이즈또는 불용어 제거하기\n",
    "- 정규표현식으로 제거할 수 없는 패턴들이 있다.\n",
    "- 특수문자와는 다르게 분석에 의미가 없는 단어들을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27adfabd-19a3-463f-bee1-5bfb1a6cff77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # 불용어 가져오는 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1d8b302-6384-4d15-8808-399675826da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3ae0dab-e57a-40cb-be47-75a7fdfd1b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c61ae970-1b1d-4e3c-a635-dd574f4ac45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('[\\W\"]+')\n",
    "tokens = tokenizer.tokenize(sp1.lower()) # 소문자로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "37697513-0580-4472-96f0-47fb79246fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = [word for word in tokens if word not in en_stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2c32475-02a7-4c16-b17e-138b25c41a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '. ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '. ',\n",
       " ' ',\n",
       " ', ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72259b0-0677-45f7-82c6-b948ceeb790b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 정규화 작업\n",
    "- 동사 변환 되는 것\n",
    "- 흔희 어간(stem) 변하지 않는 부분인 어간을 추출한다는 개념\n",
    "- 간다, 갔다, 작다, 작으니, 작고,작아서 .. 작다의 개념에서 파생\n",
    "- 포터 스테머 정규화하는 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15f00e2a-78de-44ce-a2c5-4bf80f2827bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go go goe\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer # 정규화하는 패키지\n",
    "\n",
    "stem = PorterStemmer()\n",
    "print(stem.stem('go'),stem.stem('going'),stem.stem('goes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "662ff91b-155a-4b2b-a0b0-bc9fcdfd8db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sp1)\n",
    "\n",
    "#불용어 한 것처럼 반복문으로 진행\n",
    "res1 = [stem.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a144dc9a-571c-48b9-b241-e626f34aa141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machin',\n",
       " 'learn',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'where',\n",
       " 'comput',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'data',\n",
       " 'to',\n",
       " 'discov',\n",
       " 'pattern',\n",
       " 'and',\n",
       " 'perform',\n",
       " 'task',\n",
       " 'without',\n",
       " 'be',\n",
       " 'explicitli',\n",
       " 'program',\n",
       " '.',\n",
       " 'it',\n",
       " 'enabl',\n",
       " 'comput',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'and',\n",
       " 'improv',\n",
       " 'from',\n",
       " 'experi',\n",
       " 'automat',\n",
       " '.',\n",
       " 'in',\n",
       " 'gener',\n",
       " ',',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'involv']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50385d2b-5c7c-4db1-8710-d2e6ce76409b",
   "metadata": {},
   "source": [
    "- 랭카스터 스테마\n",
    "- 결과는 포터 스테마랑은 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddd04279-3acd-42d2-887c-909db4b8a726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3039ddd9-c4f2-443f-a0a5-7184af3a3f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstem = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b95ef330-1f59-4b5b-9ef9-8347f90e2a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go going goe\n"
     ]
    }
   ],
   "source": [
    "print(lstem.stem('go'),lstem.stem('going'), lstem.stem('goes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6290c-1a33-437c-86aa-9feb01b2c637",
   "metadata": {},
   "source": [
    "### 표제어 추출 Lemmatization\n",
    "- 표제어 추출의 경우는 주어진 단어를 기본형으로 변환하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b28b1eb0-9b45-4e2f-963e-9be132982a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2b84cd0-dda6-4284-919a-efb79636f891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "58b7a21c-7f45-4c4e-a7a8-dc78fa56c357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "going\n",
      "go\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('go'))\n",
    "print(lemma.lemmatize('going'))\n",
    "print(lemma.lemmatize('goes'))\n",
    "\n",
    "print(lemma.lemmatize('going', pos = 'v')) #품사를 지정하여 뽑을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39689c-5af9-4e43-970c-8c488ce76396",
   "metadata": {},
   "source": [
    "### 품사 태깅\n",
    "- 새공책\n",
    "- '새', '공책' / '공', '책'\n",
    "- 품사를 태깅을 해서 본래 의미가 사라지지 않게 의미있는 형태소로 만드는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f0dea-d9d2-4eb4-8fed-7a6c2d9e9d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
